<!DOCTYPE html>
<html lang="en-us">
<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">

    
    <meta property="og:site_name" content="Łukasz Chrząszcz">
    <meta property="og:type" content="article">

    
    <meta property="og:image" content="https://chrzaszcz.dev/img/2019-09-kafka-streams-store-basics/background.jpg">
    <meta property="twitter:image" content="https://chrzaszcz.dev/img/2019-09-kafka-streams-store-basics/background.jpg" />
    

    
    <meta name="title" content="How to count events in Kafka Streams?" />
    <meta property="og:title" content="How to count events in Kafka Streams?" />
    <meta property="twitter:title" content="How to count events in Kafka Streams?" />
    

    
    <meta name="description" content="Kafka Streams enables you to use stateful processing via Stores. Let&#39;s go through a simple example of order-counting app and discover how Stores fit in the stream processing world">
    <meta property="og:description" content="Kafka Streams enables you to use stateful processing via Stores. Let&#39;s go through a simple example of order-counting app and discover how Stores fit in the stream processing world" />
    <meta property="twitter:description" content="Kafka Streams enables you to use stateful processing via Stores. Let&#39;s go through a simple example of order-counting app and discover how Stores fit in the stream processing world" />
    

    
    <meta property="twitter:card" content="summary" />
    
    

    <meta name="keyword"  content="blog,developer,software engineer">
    <link rel="shortcut icon" href="/img/favicon.ico">

    <title>How to count events in Kafka Streams? | Łukasz Chrząszcz Dev Blog</title>

    <link rel="canonical" href="/2019/09/kafka-streams-store-basics/">

    
    
    
    <link rel="stylesheet" href="/css/bootstrap.min.css">

    
    <link rel="stylesheet" href="/css/hugo-theme-cleanwhite.min.css">

    
    <link rel="stylesheet" href="/css/zanshang.css">

    
    <link rel="stylesheet" href="/css/font-awesome.all.min.css">

    
    

    
    <script src="/js/jquery.min.js"></script>

    
    <script src="/js/bootstrap.min.js"></script>

    
    <script src="/js/hux-blog.min.js"></script>

    
    <script src="/js/lazysizes.min.js"></script>

    
    

</head>



<script async src="https://www.googletagmanager.com/gtag/js?id=G-LCDYCK8V0V"></script>
<script>
var doNotTrack = false;
if (!doNotTrack) {
	window.dataLayer = window.dataLayer || [];
	function gtag(){dataLayer.push(arguments);}
	gtag('js', new Date());
	gtag('config', 'G-LCDYCK8V0V', { 'anonymize_ip': false });
}
</script>






<nav class="navbar navbar-default navbar-custom navbar-fixed-top">

    <div class="container-fluid">
        
        <div class="navbar-header page-scroll">
            <button type="button" class="navbar-toggle">
                <span class="sr-only">Toggle navigation</span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
            </button>
            <a class="navbar-brand" href="/">Łukasz Chrząszcz</a>
        </div>

        
        
        <div id="huxblog_navbar">
            <div class="navbar-collapse">
                <ul class="nav navbar-nav navbar-right">
                    <li>
                        <a href="/">All Posts</a>
                    </li>
                    
                        
                    
                    
		    
                        <li><a href="/about//">ABOUT</a></li>
                    
                </ul>
            </div>
        </div>
        
    </div>
    
</nav>
<script>
    
    
    
    var $body   = document.body;
    var $toggle = document.querySelector('.navbar-toggle');
    var $navbar = document.querySelector('#huxblog_navbar');
    var $collapse = document.querySelector('.navbar-collapse');

    $toggle.addEventListener('click', handleMagic)
    function handleMagic(e){
        if ($navbar.className.indexOf('in') > 0) {
        
            $navbar.className = " ";
            
            setTimeout(function(){
                
                if($navbar.className.indexOf('in') < 0) {
                    $collapse.style.height = "0px"
                }
            },400)
        }else{
        
            $collapse.style.height = "auto"
            $navbar.className += " in";
        }
    }
</script>




<style type="text/css">
    header.intro-header {
        background-image: url('/img/2019-09-kafka-streams-store-basics/background.jpg')
    }
</style>

<header class="intro-header" >

    <div class="container">
        <div class="row">
            <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
                <div class="post-heading">
                    <div class="tags">
                        
                        <a class="tag" href="/tags/kafka" title="kafka">
                            kafka
                        </a>
                        
                    </div>
                    <h1>How to count events in Kafka Streams?</h1>
                    <h2 class="subheading">Stores and aggregation in Kafka Streams</h2>
                    <span class="meta">
                        
                            Posted by 
                            
                                Łukasz Chrząszcz
                             
                            on 
                            Saturday, September 28, 2019
                            
                            
                            
                            
                    </span>
                </div>
            </div>
        </div>
    </div>
</header>




<article>
    <div class="container">
        <div class="row">

            
            <div class="
                col-lg-8 col-lg-offset-2
                col-md-10 col-md-offset-1
                post-container">

                
                <h1 id="stateful">Stateful?</h1>
<p><a href="/2019/08/kafka-streams/">In the previous post</a>, we have discussed how to define topologies in Kafka Streams to apply our processing logic to every record and send it to another topic. Examples we have run through, revolved around stateless processing, but moving forward, what if we want to aggregate some events? What if we want to calculate the average value of users&rsquo; orders in the last hour or calculate how many times did users order pizza in our pizzeria?</p>
<p>Since in Kafka we are living in an endless stream world, to achieve such aggregations we have to maintain some state to quickly apply newly arrived events and update our data. So the question is, can we introduce state to our Kafka Streams application?</p>
<p>Yes, we can, and <em>stores</em> is a mechanism enabling us to do so.</p>
<p>Today, we will analyze an example of the Kafka Streams application that leverages stores to count how many times did each user order pizza in our imaginary restaurant.</p>
<h1 id="our-app">Our App</h1>
<p>Let&rsquo;s think of a simple scenario. You run a restaurant, and you offer your customers a selection of meals including among other pasta, burgers, and pizza. You want especially to improve your pizza delivery experience, so you thought of giving something extra for customers that order a lot of pizza in your restaurant.</p>
<p>Your employees could add extra sauces, coupons, etc. to every package, but they need to know how many pizzas did the particular client order since the existence of your company, to treat better the regular customers.</p>
<p>Let&rsquo;s assume we have a stream of order events. Every event contains <code>customerId</code> and <code>meal</code> (for simplicity one order is one meal). We will create a Kafka Streams application, that selects only pizza orders and counts them based on <code>customerId</code>. As a result, we expect to receive events about the current total pizza orders for each user.</p>
<p>We can achieve logic like that with just a few lines in Kafka Streams. Take a look at the snippet below. This is the code we will be dealing with today. If you want to check the whole project, head over to <a href="https://github.com/lchrzaszcz/kafka-examples/blob/master/src/main/kotlin/dev/chrzaszcz/kafka/examples/stores/PizzaOrderCount.kt">Github</a>.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-kotlin" data-lang="kotlin"><span style="display:flex;"><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 1</span><span><span style="color:#66d9ef">val</span> builder = StreamsBuilder()
</span></span><span style="display:flex;"><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 2</span><span><span style="color:#66d9ef">val</span> messagesStream = builder.stream&lt;String, Order&gt;(<span style="color:#e6db74">&#34;Orders&#34;</span>, <span style="color:#a6e22e">Consumed</span>.with(<span style="color:#a6e22e">Serdes</span>.String(), orderSerdes))
</span></span><span style="display:flex;"><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 3</span><span>
</span></span><span style="display:flex;"><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 4</span><span>messagesStream
</span></span><span style="display:flex;"><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 5</span><span>    .filter { _, <span style="color:#66d9ef">value</span> <span style="color:#f92672">-&gt;</span> <span style="color:#66d9ef">value</span>.meal <span style="color:#f92672">==</span> <span style="color:#e6db74">&#34;pizza&#34;</span> }
</span></span><span style="display:flex;"><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 6</span><span>    .groupBy { _, <span style="color:#66d9ef">value</span> <span style="color:#f92672">-&gt;</span> <span style="color:#66d9ef">value</span>.customerId }
</span></span><span style="display:flex;"><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 7</span><span>    .count(Materialized
</span></span><span style="display:flex;"><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 8</span><span>        .`as`&lt;String, Long, KeyValueStore&lt;Bytes, ByteArray&gt;&gt; (<span style="color:#e6db74">&#34;TotalPizzaOrdersStore&#34;</span>)
</span></span><span style="display:flex;"><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 9</span><span>        .withCachingDisabled())
</span></span><span style="display:flex;"><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">10</span><span>    .toStream()
</span></span><span style="display:flex;"><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">11</span><span>    .to(<span style="color:#e6db74">&#34;TotalPizzaOrders&#34;</span>, <span style="color:#a6e22e">Produced</span>.with(<span style="color:#a6e22e">Serdes</span>.String(), <span style="color:#a6e22e">Serdes</span>.Long()))
</span></span><span style="display:flex;"><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">12</span><span>
</span></span><span style="display:flex;"><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">13</span><span><span style="color:#66d9ef">val</span> topology = builder.build()
</span></span><span style="display:flex;"><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">14</span><span>
</span></span><span style="display:flex;"><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">15</span><span>logger.info { topology.describe() }
</span></span><span style="display:flex;"><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">16</span><span>
</span></span><span style="display:flex;"><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">17</span><span><span style="color:#66d9ef">val</span> streams = KafkaStreams(topology, props)
</span></span><span style="display:flex;"><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">18</span><span>streams.start()</span></span></code></pre></div>
<p>What is important here? Let&rsquo;s see.</p>
<ul>
<li><strong>Line 1-2</strong> - We are creating a stream builder as usual. We will be fetching records from <code>Orders</code> topic. The only difference is that we have provided custom <code>Serdes</code>. The incoming events will be in JSON format, so we need a custom serializer/deserializer. It is pretty straightforward, but if you are interested in the implementation, head over to the repository and check it out.</li>
<li><strong>Line 5</strong> - We are interested only in pizza orders, hence filtering here.</li>
<li><strong>Line 6</strong> - All the incoming messages will be grouped based on a customer who ordered them. So all Bob&rsquo;s orders will end up in one group, while all Alice&rsquo;s orders will end up in another group.</li>
<li><strong>Line 7</strong> - Each group will be counted separately, and the result will be stored in a <em>store</em> called <code>TotalPizzaOrdersStore</code>. You might wonder what is with <code>.withCachingDisabled</code> method. By default, Kafka Streams uses <code>RocksDB</code> for stores, and every update requires I/O since it is stored on a disk. So to prevent the heavy load on I/O, Kafka Streams caches incoming updates on a store and occasionally flushes writes to a DB. This would result in our employees receiving an update only once in a while. We would like to receive every update immediately, so we are disabling this caching. This is also good for demonstration purposes.</li>
<li><strong>Line 10</strong> - <code>count</code> method returns a <code>KTable</code>, so if we want to operate on a stream of updates to the table, we have to convert it to <code>KStream</code> again.</li>
<li><strong>Line 11</strong> - We are taking our stream of pizza orders count updates and publish it to the <code>TotalPizzaOrders</code> topic.</li>
</ul>
<p>Let&rsquo;s run this example and see how it works. The short video below presents how does our application count pizza orders. In the top terminal, I am writing some orders for users Bob and Alice, and in the bottom terminal, you can see the updating pizza order count for them.</p>
<p>
  <img src="/img/2019-09-kafka-streams-store-basics/example-clip2.gif" alt="example-clip">

</p>
<h1 id="how-does-it-work">How does it work?</h1>
<p>The most important concept we are dealing with today is a store. It is a key-value store holding some aggregated data derived from a stream. In Kafka Streams, you can have 2 kinds of stores: local store, and global store.</p>
<h2 id="store-types">Store types</h2>
<p><strong>Local Store</strong> is a data about one particular partition from an input topic. So since every instance of your service has different partitions assigned, it has different stores with different data gathered from different partitions.</p>
<p>
  <img src="/img/2019-09-kafka-streams-store-basics/local-store.png" alt="local-store">

</p>
<p>On the other hand, there is a <strong>global store</strong>, which - as you might have guessed - is present on all Kafka Streams application instances and contains all the data across all the partitions.</p>
<p>
  <img src="/img/2019-09-kafka-streams-store-basics/global-store.png" alt="global-store">

</p>
<p>In our case, we do not need shared data between instances, so our store is a simple local store. Alice&rsquo;s data might end up in one store and Bob&rsquo;s in a totally different store.</p>
<h2 id="repartitioning">Repartitioning</h2>
<p>If that is the case, and the local store is closely connected to one of the input partitions, then what happens if you publish orders for Bob with different keys? You still need to count them as Bob&rsquo;s orders, but they might end up in different instances of your service. If that would happen we could not be able to count them. Look at the picture below.</p>
<p>
  <img src="/img/2019-09-kafka-streams-store-basics/repartitioning-wrong.png" alt="repartitioning-wrong">

</p>
<p>Each instance would know about a fraction of all Bob&rsquo;s orders, and could not say globally, how many times did he order pizza. That is why one particular user&rsquo;s order events should end up in the same instance to correctly count them, right?</p>
<p>To gather the same values in the same instance, Kafka Streams employs repartitioning. This is a mechanism that splits a topology in half. The first part sends records with a new key to an intermediate topic, and the second one fetches records from this topic and follows up with the rest of the logic. Doing this ensures that all the records with the same key end up in the same partition of the intermediate topic, so it is fetched by the same consumer.</p>
<p>Take a look at the diagram below, where the producer publishes 3 Bob&rsquo;s orders with keys <code>111</code>, <code>222</code>, and <code>333</code>. As you see, any instance can receive Bob&rsquo;s order, but as soon as they do, they change the key to the customer name and send it back to Kafka.</p>
<p>
  <img src="/img/2019-09-kafka-streams-store-basics/repartitioning-correct.png" alt="repartitioning-correct">

</p>
<p>As I said above, we can split topology in half, and it is exactly what Kafka Streams does. Let&rsquo;s print the topology and find out for ourselves:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-plaintext" data-lang="plaintext"><span style="display:flex;"><span>   Sub-topology: 0
</span></span><span style="display:flex;"><span>    Source: KSTREAM-SOURCE-0000000000 (topics: [Orders])
</span></span><span style="display:flex;"><span>      --&gt; KSTREAM-FILTER-0000000001
</span></span><span style="display:flex;"><span>    Processor: KSTREAM-FILTER-0000000001 (stores: [])
</span></span><span style="display:flex;"><span>      --&gt; KSTREAM-KEY-SELECT-0000000002
</span></span><span style="display:flex;"><span>      &lt;-- KSTREAM-SOURCE-0000000000
</span></span><span style="display:flex;"><span>    Processor: KSTREAM-KEY-SELECT-0000000002 (stores: [])
</span></span><span style="display:flex;"><span>      --&gt; KSTREAM-FILTER-0000000005
</span></span><span style="display:flex;"><span>      &lt;-- KSTREAM-FILTER-0000000001
</span></span><span style="display:flex;"><span>    Processor: KSTREAM-FILTER-0000000005 (stores: [])
</span></span><span style="display:flex;"><span>      --&gt; KSTREAM-SINK-0000000004
</span></span><span style="display:flex;"><span>      &lt;-- KSTREAM-KEY-SELECT-0000000002
</span></span><span style="display:flex;"><span>    Sink: KSTREAM-SINK-0000000004 (topic: TotalPizzaOrdersStore-repartition)
</span></span><span style="display:flex;"><span>      &lt;-- KSTREAM-FILTER-0000000005
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  Sub-topology: 1
</span></span><span style="display:flex;"><span>    Source: KSTREAM-SOURCE-0000000006 (topics: [TotalPizzaOrdersStore-repartition])
</span></span><span style="display:flex;"><span>      --&gt; KSTREAM-AGGREGATE-0000000003
</span></span><span style="display:flex;"><span>    Processor: KSTREAM-AGGREGATE-0000000003 (stores: [TotalPizzaOrdersStore])
</span></span><span style="display:flex;"><span>      --&gt; KTABLE-TOSTREAM-0000000007
</span></span><span style="display:flex;"><span>      &lt;-- KSTREAM-SOURCE-0000000006
</span></span><span style="display:flex;"><span>    Processor: KTABLE-TOSTREAM-0000000007 (stores: [])
</span></span><span style="display:flex;"><span>      --&gt; KSTREAM-SINK-0000000008
</span></span><span style="display:flex;"><span>      &lt;-- KSTREAM-AGGREGATE-0000000003
</span></span><span style="display:flex;"><span>    Sink: KSTREAM-SINK-0000000008 (topic: TotalPizzaOrders)
</span></span><span style="display:flex;"><span>      &lt;-- KTABLE-TOSTREAM-0000000007
</span></span></code></pre></div><p>At first, you see that there are two sub-topologies. As we stated previously, the first one ends up in publishing records to <code>TotalPizzaOrdersStore-repartition</code> topic, while the other one starts from fetching from <code>TotalPizzaOrdersStore-repartition</code> topic.</p>
<p>Let&rsquo;s subscribe to this internal topic to have a pick at what is sent there. The internal topic&rsquo;s name is <code>store-sample-dsl-application-TotalPizzaOrdersStore-repartition</code>. Prefix <code>store-sample-dsl-application</code> is inherited from Kafka Stream&rsquo;s application name, to prevent conflicts with other application&rsquo;s topics.</p>
<p>Take a look at the video below to check what is being sent to the repartitioning topic. As you see it is the original event, but with a key changed to the <code>customerId</code>.</p>
<p>
  <img src="/img/2019-09-kafka-streams-store-basics/repartitioning.gif" alt="repartition">

</p>
<h2 id="what-about-memory">What about memory?</h2>
<p>So far so good. We have pizza orders counts for all our users.</p>
<p>Along with being enormously satisfied with what we have achieved, we should be equally worried about the whole order history fitting into our memory, right?</p>
<p>Keeping everything in RAM, would not only be problematic but also wasteful, as a lot of customers order only once in a while. That is why Kafka Streams by default leverages <code>RocksDB</code> to store all the data on a disk.</p>
<p>I would not be myself if I would not dig into the database itself to see what is stored there. Let&rsquo;s go there together and check!</p>
<p>Usually Kafka Streams stores databases in <code>/tmp</code> directory. In our case, for application named <code>store-sample-dsl-application</code> all the databases are stored in <code>/tmp/kafka-streams/store-sample-dsl-application</code> directory.</p>
<p>Listing all the directories there shows us all the tasks that were created for our application.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-plaintext" data-lang="plaintext"><span style="display:flex;"><span>[0] % ls /tmp/kafka-streams/store-sample-dsl-application
</span></span><span style="display:flex;"><span>1_0  1_1  1_2  1_3  1_4  1_5  1_6  1_7
</span></span></code></pre></div><p>We can check the content of those directories, and in my case two of them actually contained some data. That is reasonable since we have been sending orders for Alice and Bob (and those are two different keys).</p>
<p>We can use an <code>ldb</code> tool shipped with <code>RocksDB</code> to scan the database. The printed values are a hex representation of order count with a timestamp. The first 8 bytes are a timestamp, and the rest is a count. If you are curious about the implementation, you can check the Kafka Streams source <a href="https://github.com/apache/kafka/blob/trunk/streams/src/main/java/org/apache/kafka/streams/state/internals/ValueAndTimestampSerializer.java">here</a></p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-plaintext" data-lang="plaintext"><span style="display:flex;"><span>theer@Theerpad : /tmp/kafka-streams/store-sample-dsl-application/1_7/rocksdb/TotalPizzaOrdersStore
</span></span><span style="display:flex;"><span>[0] % ldb --db=`pwd` scan --column_family=keyValueWithTimestamp --value_hex
</span></span><span style="display:flex;"><span>Bob : 0x0000016D787ABAE80000000000000022
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>theer@Theerpad : /tmp/kafka-streams/store-sample-dsl-application/1_1/rocksdb/TotalPizzaOrdersStore
</span></span><span style="display:flex;"><span>[0] % ldb --db=`pwd` scan --column_family=keyValueWithTimestamp --value_hex 
</span></span><span style="display:flex;"><span>Alice : 0x0000016D78A7D984000000000000000C
</span></span></code></pre></div><p>I was playing for a while with the application, and the last update I have received for Bob was 34 and for Alice 12. This is exactly what we can see in the snippet above in an output from <code>RocksDB</code>.</p>
<h2 id="durability">Durability</h2>
<p>A crucial thing to remember is that <code>RocksDB</code> is not used for durability. It is entirely disposable, so if you run your services on Kubernetes or similar technology you would not have to run it as a StatefulSet or provision any shared storage.</p>
<p>Does that mean in case of failure your application has to process and aggregate all events from the beginning?</p>
<p>Fortunately, no. Kafka Streams sends all values from the store after to another topic. This topic is compacted, so it keeps at least the last value for each of the keys. Given that, in case of your service failure, the new instance will just scan this changelog topic and rebuild the store.</p>
<p>In our case, this changelog topic is named <code>store-sample-dsl-application-TotalPizzaOrdersStore-changelog</code>. We can query it from beginning to see what has been sent there so far. Take a look at the snippet below (for readability, I skipped some parts with &ldquo;&hellip;&rdquo;).</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-plaintext" data-lang="plaintext"><span style="display:flex;"><span>bash-4.4# ./kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic store-sample-dsl-application-TotalPizzaOrdersStore-changelog --property print.key=true --from-beginning --value-deserializer org.apache.kafka.common.serialization.LongDeserializer
</span></span><span style="display:flex;"><span>Bob	1
</span></span><span style="display:flex;"><span>Bob	2
</span></span><span style="display:flex;"><span>Bob	3
</span></span><span style="display:flex;"><span>...
</span></span><span style="display:flex;"><span>Bob	32
</span></span><span style="display:flex;"><span>Bob	33
</span></span><span style="display:flex;"><span>Bob	34
</span></span><span style="display:flex;"><span>Alice	1
</span></span><span style="display:flex;"><span>Alice	2
</span></span><span style="display:flex;"><span>Alice	3
</span></span><span style="display:flex;"><span>...
</span></span><span style="display:flex;"><span>Alice	11
</span></span><span style="display:flex;"><span>Alice	12
</span></span></code></pre></div><p>Additionally, if you want your processing to be up-and-running even sooner, you can enable standby mode in which, every store is followed by a standby instance that is ready to take over the active one as soon as it goes down, but that is a material for future posts.</p>
<h1 id="summary">Summary</h1>
<p>I think we got a pretty decent grasp of how stateful processing looks like in Kafka Streams. Even though it was only a simple counting example, we could observe a lot of mechanisms underneath.</p>
<p>You can achieve much more in terms of aggregation in Kafka Streams by introducing moving windowing over the stream of data or joining multiple streams. We will definitely dig into that in later posts.</p>
<p>However, for today let&rsquo;s summarize what we have learned:</p>
<ul>
<li>
<p>You can easily count everything since the beginning of your stream.</p>
</li>
<li>
<p>You can receive all the updates on a particular count value on another Kafka topic.</p>
</li>
<li>
<p>There are two store types: global store, and local store.</p>
</li>
<li>
<p>The Global store is present in all instances and has the same data.</p>
</li>
<li>
<p>The Local store is unique for every input partition, and instances have different stores, due to different partition assignment.</p>
</li>
<li>
<p>Counting requires gathering all events that need to be counted together in one instance, so if the input topic has a different partitioning key than the required grouping key, Kafka Streams has to perform repartitioning.</p>
</li>
<li>
<p>Repartitioning is basically just changing the key of the record to the chosen grouping key, and sending it to intermediate Kafka topic, so the events that have the same grouping key will end up on the same partition, hence the same instance.</p>
</li>
<li>
<p>Stores are not stored entirely in RAM. They are stored on a disk leveraging <code>RocksDB</code>.</p>
</li>
<li>
<p><code>RocksDB</code> is not used for increased durability. It is simply a way to fit the huge datasets next to the application.</p>
</li>
<li>
<p>To prevent data loss, Kafka Streams sends all updates to the store value to the <code>changelog</code> topic. In case of a failure, another instance will take over the task, and restore the database from this <code>changelog</code> topic.</p>
</li>
</ul>
<p>Thank you for reading the post. Please share your thoughts and comments, so I can improve future articles, and share knowledge with you in the best way I can 😄</p>


                

                
                <hr>
                <ul class="pager">
                    
                    <li class="previous">
                        <a href="/2019/08/kafka-streams/" data-toggle="tooltip" data-placement="top" title="How to use Kafka Streams to process events from one topic to another?">&larr;
                            Previous Post</a>
                    </li>
                    
                    
                    <li class="next">
                        <a href="/2019/12/kafka-transactions/" data-toggle="tooltip" data-placement="top" title="How do transactions work in Apache Kafka?">Next
                            Post &rarr;</a>
                    </li>
                    
                </ul>
                

                


<div id="disqus-comment"></div>
<div id="disqus_thread"></div>
<script type="application/javascript">
    window.disqus_config = function () {
    
    
    
    };
    (function() {
        if (["localhost", "127.0.0.1"].indexOf(window.location.hostname) != -1) {
            document.getElementById('disqus_thread').innerHTML = 'Disqus comments not available by default when the website is previewed locally.';
            return;
        }
        var d = document, s = d.createElement('script'); s.async = true;
        s.src = '//' + "theer108" + '.disqus.com/embed.js';
        s.setAttribute('data-timestamp', +new Date());
        (d.head || d.body).appendChild(s);
    })();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
<a href="https://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>



            </div>

            
            

            
            <div class="
                col-lg-8 col-lg-offset-2
                col-md-10 col-md-offset-1
                sidebar-container">

                
                
                <section>
                    <hr class="hidden-sm hidden-xs">
                    <h5><a href="/tags/">FEATURED TAGS</a></h5>
                    <div class="tags">
                        
                        
                        
                        <a href="/tags/book" title="book">
                            book
                        </a>
                        
                        
                        
                        <a href="/tags/docker" title="docker">
                            docker
                        </a>
                        
                        
                        
                        <a href="/tags/kafka" title="kafka">
                            kafka
                        </a>
                        
                        
                        
                        <a href="/tags/soft-skills" title="soft-skills">
                            soft-skills
                        </a>
                        
                        
                    </div>
                </section>
                

                
                
            </div>
        </div>
    </div>
</article>




<footer>
    <div class="container">
        <div class="row">
            <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
                <ul class="list-inline text-center">                  
                    
                    
                    
                    
                    

		            
                    
                    
                    <li>
                        <a target="_blank" href="https://github.com/lchrzaszcz">
                            <span class="fa-stack fa-lg">
                                <i class="fas fa-circle fa-stack-2x"></i>
                                <i class="fab fa-github fa-stack-1x fa-inverse"></i>
                            </span>
                        </a>
                    </li>
		            
                    
                    
                    
                    <li>
                        <a target="_blank" href="https://www.linkedin.com/in/%C5%82ukasz-chrz%C4%85szcz-502733b9/">
                            <span class="fa-stack fa-lg">
                                <i class="fas fa-circle fa-stack-2x"></i>
                                <i class="fab fa-linkedin fa-stack-1x fa-inverse"></i>
                            </span>
                        </a>
                    </li>
		           
                    
                    
                    
                    
                    
                    
            
            
            <li>
                <a target="_blank" href="https://www.instagram.com/chrzaszcz.dev/">
                    <span class="fa-stack fa-lg">
                        <i class="fas fa-circle fa-stack-2x"></i>
                        <i class="fab fa-instagram fa-stack-1x fa-inverse"></i>
                    </span>
                </a>
            </li>
            
            
           
                   <li>
                       <a href='' rel="alternate" type="application/rss+xml" title="Łukasz Chrząszcz" >
                           <span class="fa-stack fa-lg">
                               <i class="fas fa-circle fa-stack-2x"></i>
                               <i class="fas fa-rss fa-stack-1x fa-inverse"></i>
                           </span>
                       </a>
                   </li>
            
             </ul>
		<p class="copyright text-muted">
                    Copyright &copy; Łukasz Chrząszcz 2023
                    <br>
                    <a href="https://themes.gohugo.io/hugo-theme-cleanwhite">CleanWhite Hugo Theme</a> by <a href="https://zhaohuabing.com">Huabing</a> |
                    <iframe
                        style="margin-left: 2px; margin-bottom:-5px;"
                        frameborder="0" scrolling="0" width="100px" height="20px"
                        src="https://ghbtns.com/github-btn.html?user=zhaohuabing&repo=hugo-theme-cleanwhite&type=star&count=true" >
                    </iframe>
                </p>
            </div>
        </div>
    </div>
</footer>




<script>
    function loadAsync(u, c) {
      var d = document, t = 'script',
          o = d.createElement(t),
          s = d.getElementsByTagName(t)[0];
      o.src = u;
      if (c) { o.addEventListener('load', function (e) { c(null, e); }, false); }
      s.parentNode.insertBefore(o, s);
    }
</script>






<script>
    
    if($('#tag_cloud').length !== 0){
        loadAsync("/js/jquery.tagcloud.js",function(){
            $.fn.tagcloud.defaults = {
                
                color: {start: '#bbbbee', end: '#0085a1'},
            };
            $('#tag_cloud a').tagcloud();
        })
    }
</script>


<script>
    loadAsync("https://cdn.jsdelivr.net/npm/fastclick@1.0.6/lib/fastclick.min.js", function(){
        var $nav = document.querySelector("nav");
        if($nav) FastClick.attach($nav);
    })
</script>











</body>
</html>
