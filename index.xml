<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>≈Åukasz ChrzƒÖszcz</title>
    <link>http://chrzaszcz.dev/</link>
    <description>Recent content on ≈Åukasz ChrzƒÖszcz</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Sun, 01 Dec 2019 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="http://chrzaszcz.dev/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>How do transactions work in Apache Kafka?</title>
      <link>http://chrzaszcz.dev/2019/12/kafka-transactions/</link>
      <pubDate>Sun, 01 Dec 2019 00:00:00 +0000</pubDate>
      
      <guid>http://chrzaszcz.dev/2019/12/kafka-transactions/</guid>
      <description>When you first encounter Kafka, you will face either at-least-once, or at-most-once guarantees, depending on when you commit your offsets. This is sufficient for many or even most use cases. However, if you are processing events from one topic to another, you might worry about the duplication of your messages on the target topic, or lost events on the source topic. A solution to that problem is a transaction.
What can we expect from Kafka&#39;s transactions?</description>
    </item>
    
    <item>
      <title>How to count events in Kafka Streams?</title>
      <link>http://chrzaszcz.dev/2019/09/kafka-streams-store-basics/</link>
      <pubDate>Sat, 28 Sep 2019 00:00:00 +0000</pubDate>
      
      <guid>http://chrzaszcz.dev/2019/09/kafka-streams-store-basics/</guid>
      <description>Stateful? In the previous post, we have discussed how to define topologies in Kafka Streams to apply our processing logic to every record and send it to another topic. Examples we have run through, revolved around stateless processing, but moving forward, what if we want to aggregate some events? What if we want to calculate the average value of users&amp;rsquo; orders in the last hour or calculate how many times did users order pizza in our pizzeria?</description>
    </item>
    
    <item>
      <title>How to use Kafka Streams to process events from one topic to another?</title>
      <link>http://chrzaszcz.dev/2019/08/kafka-streams/</link>
      <pubDate>Tue, 06 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>http://chrzaszcz.dev/2019/08/kafka-streams/</guid>
      <description>What is Kafka Streams? We have already discussed a lot about producers and consumers. We know that we can take a consumer, poll for some messages, transform them, and finally publish the result on another topic.
As simple as it sounds it might get boring to write yet another thread that does the fetching, processing, error handling, and again and again. Not only it is cumbersome, but also error-prone.
Is there a better way?</description>
    </item>
    
    <item>
      <title>What happens when a new consumer joins the group in Kafka?</title>
      <link>http://chrzaszcz.dev/2019/06/kafka-rebalancing/</link>
      <pubDate>Sun, 14 Jul 2019 00:00:00 +0000</pubDate>
      
      <guid>http://chrzaszcz.dev/2019/06/kafka-rebalancing/</guid>
      <description>What is a rebalancing? As you know, all messages on a topic are spread out among the members of consumer group. Every consumer has its set of partitions assigned exclusively to it and rebalancing is all about maintaining all partitions assigned to active consumers.
When one consumer dies Kafka needs to reassign orphaned partitions to the rest of the consumers. Similarly, when a new consumer joins the group Kafka needs to free up some partitions and assign them to the new consumers (if it can).</description>
    </item>
    
    <item>
      <title>What does the heartbeat thread do in Kafka Consumer?</title>
      <link>http://chrzaszcz.dev/2019/06/kafka-heartbeat-thread/</link>
      <pubDate>Sat, 22 Jun 2019 00:00:00 +0000</pubDate>
      
      <guid>http://chrzaszcz.dev/2019/06/kafka-heartbeat-thread/</guid>
      <description>Recap In the previous post we&#39;ve discussed how does Kafka Consumer work underneath. Now we know what are the very first steps to fetch records.
Remember what I&#39;ve intentionally omitted from previous post? That&#39;s right! Heartbeat thread. We will investigate what it does exactly and how it works in general.
Samples and setup If you want to run some samples on debug to discover heartbeat code by yourself, please by all means use my simple project on this GitHub repo.</description>
    </item>
    
    <item>
      <title>What happens when you call poll on Kafka Consumer?</title>
      <link>http://chrzaszcz.dev/2019/06/16/kafka-consumer-poll/</link>
      <pubDate>Sun, 16 Jun 2019 00:00:00 +0000</pubDate>
      
      <guid>http://chrzaszcz.dev/2019/06/16/kafka-consumer-poll/</guid>
      <description>Recap In the previous post we&#39;ve discussed what Kafka is and how to interact with it. We explored how consumers subscribe to the topic and consume messages from it. We know that consumers form a group called consumer group and that Kafka split messages among members of the consumer group.
That&#39;s of course after the initialization is finished, but what exactly is done in the background when you create a new consumer and call the very first poll?</description>
    </item>
    
    <item>
      <title>Kafka 101</title>
      <link>http://chrzaszcz.dev/2019/05/26/kafka-101/</link>
      <pubDate>Sun, 26 May 2019 00:00:00 +0000</pubDate>
      
      <guid>http://chrzaszcz.dev/2019/05/26/kafka-101/</guid>
      <description>What is Kafka? Kafka is a popular stream-processing platform. What does it mean? You can think of it as a service that takes messages from one place and put it in another. It allows you to construct asynchronous processing of events, create pub-sub mechanism or distribute work evenly among worker services - the are many use cases for it.
Whatever your use case is, you need to know a few basic ideas about Kafka.</description>
    </item>
    
    <item>
      <title>Introduction to Docker</title>
      <link>http://chrzaszcz.dev/2019/05/19/introduction-to-docker/</link>
      <pubDate>Sat, 18 May 2019 00:00:00 +0000</pubDate>
      
      <guid>http://chrzaszcz.dev/2019/05/19/introduction-to-docker/</guid>
      <description>Docker! That‚Äôs a real buzzword today! If you haven‚Äôt had a chance to use it yet, then you probably wonder what problems does it solve and if it can come in handy for you? Have you ever struggled with the problem of installing new software just for trying something out? Doing this regularly can lead to chaos in your OS not to mention the extra hassle of configuring more complex or coupled software (Wordpress with LAMP).</description>
    </item>
    
    <item>
      <title></title>
      <link>http://chrzaszcz.dev/top/about/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://chrzaszcz.dev/top/about/</guid>
      <description>Hi!
I am a software engineer - since I was 9 üòÑ.
What can I say about myself? I always want to reach deeper understanding of the stuff I am dealing with. How exactly is rebalancing in Kafka implemented? How does Zookeeper reach its consensus? Those are the questions that inspire me to dig in the code and share my findings with others.
In my opinion the most important virtue of a software engineer is eagerness to understand the principles that drive almost all technologies, since libraries, frameworks, and databases come and go, but principles last forever.</description>
    </item>
    
  </channel>
</rss>